Téléchargez et déposez ici le ou les modèles utilisés.

Les modèles utilisés sont ceux au format GGUF mis à disposition sur Hugging Face par TheBloke.

Par exemple pour "Mistral-7B-Instruct" au format GGUF avec une quantization Q5_K_M : 

https://huggingface.co/TheBloke/Mistral-7B-Instruct-v0.1-GGUF/blob/main/mistral-7b-instruct-v0.1.Q5_K_M.gguf

